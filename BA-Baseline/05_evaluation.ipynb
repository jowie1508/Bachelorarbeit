{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trainings process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluation of P-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluation of PF-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Time series plots for both, P and PF models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep this notebook clearly readable, some functions are outsourced in utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/models/history/P_optimized_3_history.pkl', 'rb') as f:\n",
    "    history_P_opt = pickle.load(f)\n",
    "with open('data/models/history/PF_optimized_2_history.pkl', 'rb') as f:\n",
    "    history_PF_opt = pickle.load(f) \n",
    "with open('data/models/history/P_optimized_final_history.pkl', 'rb') as f:\n",
    "    history_P = pickle.load(f)\n",
    "with open('data/models/history/PF_optimized_final_history.pkl', 'rb') as f:\n",
    "    history_PF_s = pickle.load(f) \n",
    "\n",
    "model_P = load_model('data/models/GRU_P_final.h5')\n",
    "model_PF = load_model('data/models/GRU_PF_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Trainingsprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_training_history\n",
    "\n",
    "plot_training_history(history_P_opt, history_PF_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. P-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import data_loader\n",
    "from utils.utils import train_test_val_data\n",
    "import config\n",
    "\n",
    "# load data\n",
    "data = data_loader(config.columns_P)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_val_data(df_scaled, \n",
    "                                                                     len(data.index.unique()), \n",
    "                                                                     1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import inverse_transform, get_monthly_metrics\n",
    "\n",
    "# Vorhersagen auf den Testdaten machen\n",
    "y_predicted = model_P.predict(X_test)\n",
    "print(\"Shape predicted_test {}\".format(y_predicted.shape))\n",
    "print(\"Shape y_test {}\".format(y_test.shape))\n",
    "\n",
    "actual_values_p, predictions_p, X_test_actual_p = inverse_transform(y_predicted, y_test, X_test, scaler, config.columns_P, 1, \"P_TOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import inverse_transform, get_monthly_metrics\n",
    "get_monthly_metrics(X_test_actual_p, actual_values_p, predictions_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_predictions_vs_test, plot_predictions_vs_test_sequence\n",
    "plot_predictions_vs_test(actual_values_p, predictions_p, X_test_actual_p, 99, multiplier=1.8, window_length=5, traces={\"smoothing\": False, \"boosting\": False})\n",
    "plot_predictions_vs_test(actual_values_p, predictions_p, X_test_actual_p, 4, multiplier=1.8, window_length=5, traces={\"smoothing\": True, \"boosting\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_test_sequence(X_test_actual_p, actual_values_p, predictions_p, 4093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. PF-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = data_loader(config.columns_PF)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_val_data(df_scaled, \n",
    "                                                                     len(data.index.unique()), \n",
    "                                                                     1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen auf den Testdaten machen\n",
    "y_predicted_PF = model_PF.predict(X_test)\n",
    "print(\"Shape predicted_test {}\".format(y_predicted_PF.shape))\n",
    "print(\"Shape y_test {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values_PF, predictions_PF, X_test_actual_PF = inverse_transform(y_predicted_PF, y_test, X_test, scaler, config.columns_PF, 1, \"PF_TOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_metrics = get_monthly_metrics(X_test_actual_PF, actual_values_PF, predictions_PF)\n",
    "monthly_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_utils import plot_comparison\n",
    "plot_comparison(\n",
    "    actual_values_p, predictions_p, X_test_actual_p, \n",
    "    actual_values_PF, predictions_PF, X_test_actual_PF, \n",
    "    80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
