{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Datenqualität Wärmepumpendaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Globale Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_START = 1525270500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "with open('Data/heatpump/data_heatpump.pkl', 'rb') as f:\n",
    "    load_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen eines Dataframes, welcher zur Analyse fehlender bzw. nan Zellen dient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = load_dict['SFH10']['index'].to_frame()\n",
    "for df in load_dict:\n",
    "    load_dict[df][df] = load_dict[df]['P_TOT'].apply(check_nan)\n",
    "    df_result = pd.concat([df_result, load_dict[df][df]], axis=1)\n",
    "df_result.set_index('index', inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_availability_histogramm(df):\n",
    "    # Datenverfügbarkeit berechnen\n",
    "    data_availability = df.mean(axis=0)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Farben festlegen\n",
    "    colors = ['#ff9999' if value < 1 else '#66b266' for value in data_availability]\n",
    "\n",
    "    # Horizontales Balkendiagramm zeichnen\n",
    "    data_availability.plot(kind='barh', color=colors, ax=ax)\n",
    "\n",
    "    # Achsentitel und Plot-Titel hinzufügen\n",
    "    ax.set_title('Datenverfügbarkeit')\n",
    "    ax.set_ylabel('Objekte')\n",
    "    ax.set_xlabel('Verfügbarkeit in %')\n",
    "    ax.set_xlim(0, 1)  # x-Achse auf den Bereich 0 bis 1 setzen\n",
    "\n",
    "    # Anzeigen\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_availability_histogramm(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop functions to analize intervalls with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = df_result['SFH10'].to_frame()\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_intervalls(df, column):\n",
    "    streak = False\n",
    "    complete = False\n",
    "    intervall_list = []\n",
    "    for index, value in df.iterrows():\n",
    "        if value.values[0] == 0:\n",
    "            if streak == True:\n",
    "                continue\n",
    "            else:\n",
    "                streak = True\n",
    "                start = index\n",
    "        if value.values[0] == 1:\n",
    "            if streak == True:\n",
    "                end = index-900\n",
    "                complete = True\n",
    "            \n",
    "\n",
    "        if complete == True:\n",
    "                print(\"entered complete\")\n",
    "                intervall_list.append([start, end])\n",
    "                streak = False\n",
    "                complete = False\n",
    "    \n",
    "    return intervall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missing_intervalls(df_10, 'SFH10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for row, column in df_10.iterrows():\n",
    "    if counter > 1:\n",
    "        break\n",
    "\n",
    "    #print(row)\n",
    "    print(row)\n",
    "    print(column.values[0])\n",
    "    counter +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Erstellen Sie ein Beispiel-DataFrame basierend auf Ihrem gegebenen Bild\n",
    "#data = {\n",
    "#    'SFH10': [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
    "#}\n",
    "#index = [1514764800, 1514765700, 1514766600, 1514767500, 1514768400, 1609454700, 1609455600, 1609456500, 1609457400, 1609458300, 1609459200]\n",
    "#df = pd.DataFrame(data, index=index)\n",
    "\n",
    "df = df_10.copy()\n",
    "\n",
    "# Gruppen von zusammenhängenden Nullen identifizieren\n",
    "df['group'] = (df['SFH10'] != df['SFH10'].shift()).cumsum()\n",
    "zero_groups = df[df['SFH10'] == 0].groupby('group')\n",
    "\n",
    "# Start- und Endindizes von zusammenhängenden Nullen ausgeben\n",
    "result = []\n",
    "for name, group in zero_groups:\n",
    "    start_index = group.index[0]\n",
    "    end_index = group.index[-1]\n",
    "    result.append((start_index, end_index))\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_intervalls(df, column):\n",
    "    # Gruppen von zusammenhängenden Nullen identifizieren\n",
    "    df['group'] = (df[column] != df[column].shift()).cumsum()\n",
    "    zero_groups = df[df[column] == 0].groupby('group')\n",
    "    # Start- und Endindizes von zusammenhängenden Nullen ausgeben\n",
    "    result = []\n",
    "    for name, group in zero_groups:\n",
    "        start_index = group.index[0]\n",
    "        end_index = group.index[-1]\n",
    "        result.append((start_index, end_index))\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_missing_intervalls_length(tuple):\n",
    "    length = tuple[1] - tuple[0]\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of missing intervalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.set_index('index', inplace=True)\n",
    "\n",
    "for column in df_result.columns:\n",
    "    df = df_result[column].to_frame()\n",
    "    intervalls = get_missing_intervalls(df, column)\n",
    "    print(column + \": \" + str(intervalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce dataframe to common start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for column in df_result.columns:\n",
    "    df = df_result[column].to_frame()\n",
    "    intervalls = get_missing_intervalls(df, column)\n",
    "\n",
    "    if counter == 0:\n",
    "        begin_index = intervalls[0][1]\n",
    "        counter = 1\n",
    "    else:\n",
    "        if intervalls[0][1] < begin_index:\n",
    "            print(column + \" \" + str(intervalls[0][1]))\n",
    "            begin_index = intervalls[0][1]\n",
    "\n",
    "print(begin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_result[df_result.index >= 1525270500]\n",
    "\n",
    "for row,value in test.iterrows():\n",
    "    if test.loc[row].sum() > 30:\n",
    "        print(\">30: \" + str(row))\n",
    "        start_index = row\n",
    "        break\n",
    "\n",
    "df_final = df_result[df_result.index >= start_index]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_availability_histogramm(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_data_availability(df):\n",
    "    # Datenkonvertierung: Unix-Timestamp zu Datum\n",
    "    df.index = pd.to_datetime(df.index, unit='s')\n",
    "\n",
    "    # Reihenfolge der Spalten nach den Zahlen in den Objektbezeichnungen sortieren\n",
    "    sorted_columns = sorted(df.columns, key=lambda x: int(x.replace(\"SFH\", \"\")))\n",
    "\n",
    "    # Prozentsätze für jede Spalte berechnen\n",
    "    percentages = (df.sum() / len(df) * 100).round(2)\n",
    "    percentages = percentages[sorted_columns]\n",
    "\n",
    "    # Plot-Einstellungen, Verkleinerung der Figur\n",
    "    fig, ax = plt.subplots(figsize=(7, 8))  # Kleinere Figurgröße\n",
    "\n",
    "    # Durch jede sortierte Spalte iterieren und Datenverfügbarkeit zeichnen\n",
    "    for i, column in enumerate(sorted_columns):\n",
    "        # Datenverfügbarkeit\n",
    "        ax.fill_between(df.index, i, i + 1, where=(df[column] == 1), color='#66D37A', step='mid')\n",
    "        # Fehlende Daten\n",
    "        ax.fill_between(df.index, i, i + 1, where=(df[column] == 0), color='#FF5252', step='mid')\n",
    "        # Prozentsatz neben jedem Balken hinzufügen (mit zusätzlichem Leerzeichen und Abstand nach rechts)\n",
    "        ax.text(df.index[-1] + pd.Timedelta(days=1), i + 0.5, f\" {percentages[column]}%\", verticalalignment='center', horizontalalignment='left')\n",
    "\n",
    "    # Einstellungen\n",
    "    # Anpassung der x-Limits, um den Platz für die Prozentsätze zu berücksichtigen\n",
    "    ax.set_xlim([df.index.min(), df.index.max() + pd.Timedelta(days=1)])  # Reduzierter Platz für Prozentsätze\n",
    "    ax.set_ylim([0, len(sorted_columns)])\n",
    "    ax.set_yticks(np.arange(len(sorted_columns)) + 0.5)\n",
    "    ax.set_yticklabels(sorted_columns)\n",
    "    ax.set_title(\"Data Availability\")\n",
    "    ax.set_xlabel(\"Timestamps\")\n",
    "    ax.set_ylabel(\"Objects\")\n",
    "\n",
    "    # Farblegende hinzufügen\n",
    "    ax.legend(handles=[plt.Line2D([0], [0], color='#66D37A', label='Available'),\n",
    "                    plt.Line2D([0], [0], color='#FF5252', label='Missing')], loc='upper right')\n",
    "\n",
    "    # Erweiterte Datumseinstellungen für die X-Achse mit 3-monatigem Intervall\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_availability(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closer look at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev with complete data of house SFH3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = load_dict[\"SFH3\"]\n",
    "df_3 = df_3[df_3['index']>INDEX_START]\n",
    "df_3.set_index('index', inplace=True)\n",
    "df_3.index = pd.to_datetime(df_3.index, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of all available data for whole timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumption_plot(data, name):\n",
    "    df = data.copy()\n",
    "    # Erstelle eine Figur mit sekundärer Y-Achse\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Füge die Kurven für P_TOT, Q_TOT, und S_TOT zur linken Y-Achse hinzu\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['index'], y=df['P_TOT'], name='P_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['index'], y=df['Q_TOT'], name='Q_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['index'], y=df['S_TOT'], name='S_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    # Füge die Kurve für PF_TOT zur rechten Y-Achse hinzu\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['index'], y=df['PF_TOT'], name='PF_TOT', line=dict(dash='dot')),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    # Benenne die Achsen\n",
    "    fig.update_xaxes(title_text='Zeit')\n",
    "    fig.update_yaxes(title_text='P_TOT, Q_TOT, S_TOT', secondary_y=False)\n",
    "    fig.update_yaxes(title_text='PF_TOT', secondary_y=True)\n",
    "    # Füge einen Titel hinzu und passe das Layout an\n",
    "    fig.update_layout(\n",
    "        title_text='Zeitliche Darstellung der Werte - {}'.format(name),\n",
    "        xaxis=dict(\n",
    "            tickmode='auto',\n",
    "            nticks=20,\n",
    "            ticks='outside',\n",
    "            tickson='boundaries',\n",
    "            ticklen=20\n",
    "        )\n",
    "    )\n",
    "    # Zeige die Figur an\n",
    "    fig.show()\n",
    "\n",
    "create_consumption_plot(df_3, 'SFH3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampled version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "# Angenommen, df ist dein DataFrame.\n",
    "# df = df_3.copy()\n",
    "\n",
    "def create_resampled_consumption_plot(data, name):\n",
    "    # Stelle sicher, dass 'index' in datetime umgewandelt wird und als Index gesetzt wird\n",
    "    df = data.copy()\n",
    "    df['index'] = pd.to_datetime(df['index'])\n",
    "    df.set_index('index', inplace=True)\n",
    "\n",
    "    # Resample der Daten auf 24-Stunden-Intervalle und berechne den Durchschnitt\n",
    "    df_resampled = df.resample('24H').mean().reset_index()\n",
    "\n",
    "    # Erstelle eine Figur mit sekundärer Y-Achse\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Füge die Kurven für P_TOT, Q_TOT, und S_TOT zur linken Y-Achse hinzu\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_resampled['index'], y=df_resampled['P_TOT'], name='P_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_resampled['index'], y=df_resampled['Q_TOT'], name='Q_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_resampled['index'], y=df_resampled['S_TOT'], name='S_TOT'),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # Füge die Kurve für PF_TOT zur rechten Y-Achse hinzu\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_resampled['index'], y=df_resampled['PF_TOT'], name='PF_TOT', line=dict(dash='dot')),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # Benenne die Achsen\n",
    "    fig.update_xaxes(title_text='Zeit')\n",
    "    fig.update_yaxes(title_text='P_TOT, Q_TOT, S_TOT', secondary_y=False)\n",
    "    fig.update_yaxes(title_text='PF_TOT', secondary_y=True)\n",
    "\n",
    "    # Füge einen Titel hinzu und passe das Layout an\n",
    "    fig.update_layout(\n",
    "        title_text='Zeitliche Darstellung der Werte mit 24-Stunden-Intervallen - {}'.format(name),\n",
    "        xaxis=dict(\n",
    "            tickmode='auto',\n",
    "            nticks=20,\n",
    "            ticks='outside',\n",
    "            tickson='boundaries',\n",
    "            ticklen=20\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Zeige die Figur an\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(string):\n",
    "    # Finde alle Zahlen im String und verbinde sie\n",
    "    number = int(re.search(r'\\d+', string).group())\n",
    "    return number\n",
    "\n",
    "list_strings = list(load_dict.keys())\n",
    "sorted_keys = sorted(list_strings, key=sort_key)\n",
    "\n",
    "for key in sorted_keys:\n",
    "    sub_df = load_dict[key]\n",
    "    sub_df = sub_df[sub_df['index']>INDEX_START]\n",
    "    sub_df.set_index('index', inplace=True)\n",
    "    sub_df.index = pd.to_datetime(sub_df.index, unit='s')\n",
    "    sub_df.reset_index(inplace=True)\n",
    "    create_resampled_consumption_plot(sub_df, key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots pro Jahr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year(df_year, year, name):\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df_year['index'], y=df_year['P_TOT'], name='P_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year['index'], y=df_year['Q_TOT'], name='Q_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year['index'], y=df_year['S_TOT'], name='S_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year['index'], y=df_year['PF_TOT'], name='PF_TOT', line=dict(dash='dot')), secondary_y=True)\n",
    "    \n",
    "    # Update the layout for the subplot\n",
    "    fig.update_yaxes(title_text='P_TOT, Q_TOT, S_TOT', secondary_y=False)\n",
    "    fig.update_yaxes(title_text='PF_TOT', secondary_y=True)\n",
    "    fig.update_xaxes(title_text='Zeit')\n",
    "\n",
    "    # Füge einen Titel hinzu und passe das Layout an\n",
    "    fig.update_layout(height=600, width=1200, title_text=f'Daten für das Jahr {year} - {name}')\n",
    "    \n",
    "    # Zeige die Figur an\n",
    "    fig.show()\n",
    "\n",
    "def create_plot_per_year(data, name, years=[2018,2019,2020]):\n",
    "    df = data.copy()\n",
    "    df['index'] = pd.to_datetime(df['index'])\n",
    "\n",
    "    # Filtere die Daten nach Jahr\n",
    "    for year in years:\n",
    "        df_year = df[df['index'].dt.year == year]\n",
    "        plot_year(df_year, year, name)\n",
    "\n",
    "#create_plot_per_year(df_3, 'SFH3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung der Plots mit 24-stündiger Auflösung\n",
    "def create_resampled_plot_per_year(data, year, name):\n",
    "    df = data.copy()\n",
    "    df['index'] = pd.to_datetime(df['index'])\n",
    "    df.set_index('index', inplace=True)\n",
    "    # Resample der Daten auf 24-Stunden-Intervalle und berechne den Durchschnitt\n",
    "    df_resampled = df.resample('24H').mean()\n",
    "    \n",
    "    # Filtere nur das gewünschte Jahr\n",
    "    df_year = df_resampled[df_resampled.index.year == year]\n",
    "\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Füge die Daten zur Figur hinzu\n",
    "    fig.add_trace(go.Scatter(x=df_year.index, y=df_year['P_TOT'], name='P_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year.index, y=df_year['Q_TOT'], name='Q_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year.index, y=df_year['S_TOT'], name='S_TOT'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=df_year.index, y=df_year['PF_TOT'], name='PF_TOT', line=dict(dash='dot')), secondary_y=True)\n",
    "\n",
    "    # Aktualisiere die Layout-Einstellungen\n",
    "    fig.update_layout(title_text=f\"Durchschnittliche Werte in 24-Stunden-Intervallen für das Jahr {year} - {name}\",\n",
    "                      height=600, width=1400)\n",
    "    fig.update_yaxes(title_text='P_TOT, Q_TOT, S_TOT', secondary_y=False)\n",
    "    fig.update_yaxes(title_text='PF_TOT', secondary_y=True)\n",
    "\n",
    "    # Zeige die Figur an\n",
    "    fig.show()\n",
    "\n",
    "# Erzeuge die Plots für jedes Jahr\n",
    "create_resampled_plot_per_year(df, 2018, 'SFH3')\n",
    "create_resampled_plot_per_year(df, 2019, 'SFH3')\n",
    "create_resampled_plot_per_year(df, 2020, 'SFH3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
