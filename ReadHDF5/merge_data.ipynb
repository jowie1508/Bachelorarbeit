{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Read in prepared load and weather data, create a consistent 15 min intervall index by averaging the available weather data for the 15 min timespan, filling missing values with previous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) analyse different weather parameters, statistical measures and data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt weather index and merge weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in weather and heatpump data\n",
    "# adapts weather index to load index by taking the mean value of 15 minute intervalls\n",
    "# if weather data is not available (due to higher time stamp differences) the previous value is taken for the timestamp\n",
    "\n",
    "with open('Data/heatpump/data_heatpump.pkl', 'rb') as f:\n",
    "    load_dict = pickle.load(f)\n",
    "with open('Data/weather/data_weather.pkl', 'rb') as f:\n",
    "    weather_dict = pickle.load(f)\n",
    "\n",
    "ref_index = load_dict['SFH10']['index']\n",
    "df_list = []\n",
    "for df_type in weather_dict:\n",
    "    df_ref = ref_index.to_frame().set_index('index')\n",
    "    df_ref[df_type] = np.nan\n",
    "    df_temp = weather_dict[df_type]\n",
    "    for index in ref_index:\n",
    "        sub_df = df_temp[(df_temp['index'] >= index) & (df_temp['index'] <= index+900)]\n",
    "        if sub_df.empty:\n",
    "            #take previous value\n",
    "            df_ref.loc[index][df_type] = df_ref.loc[index-900][df_type]\n",
    "        else:\n",
    "            #take mean value\n",
    "            df_ref.loc[index][df_type] = sub_df.iloc[:,1].mean()\n",
    "    df_list.append(df_ref)\n",
    "weather_data = pd.concat(df_list, axis=1)\n",
    "with open('Data/weather/data_weather_merged.pkl', 'wb') as f:\n",
    "    pickle.dump(weather_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/weather/data_weather_merged.pkl', 'rb') as f:\n",
    "    weather_data = pickle.load(f)\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame(columns=weather_data.columns, index=['min', 'max', 'mean', 'median', 'missing values'])\n",
    "for column in weather_data.columns:\n",
    "    df_analysis.loc['min'][column] = weather_data[column].min()\n",
    "    df_analysis.loc['max'][column] = weather_data[column].max()\n",
    "    df_analysis.loc['mean'][column] = weather_data[column].mean()\n",
    "    df_analysis.loc['median'][column] = weather_data[column].median()\n",
    "    df_analysis.loc['missing values'][column] = len(weather_data) - weather_data[column].value_counts().sum()\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plots = weather_data.copy()\n",
    "data_plots.reset_index(inplace=True)\n",
    "data_plots['index'] = pd.to_datetime(data_plots['index'], unit='s')\n",
    "data_plots.set_index('index', inplace=True)\n",
    "\n",
    "fig, a = plt.subplots(5, 2, figsize=(20, 20), tight_layout=True)\n",
    "data_plots.plot(ax=a, subplots=True, rot=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of merged load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "with open('Data/heatpump/data_heatpump.pkl', 'rb') as f:\n",
    "    load_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = load_dict['SFH10'][['index', 'S_TOT', 'Q_TOT', 'P_TOT', 'PF_TOT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10['P_TOT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10['P_TOT'].info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
