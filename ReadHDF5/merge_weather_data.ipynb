{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read HDF5 file, convert to pandas format, concat data for 2018-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Read in the weather data in hdf5 format, each year stored in a seperate file, and convert the data format to a python dictionary containing the weather data over the available time span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Some data exploration for the weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merge all weather data features to one dataframe with continuos 15 min timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Some more data exploration containing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - the visualization of each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a correlation analysis of the parameters, concluding that only 8 of 10 parameters are relevant for further use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4. Additional code used to check code functionality and data quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf_to_pandas(hdf_dataset):\n",
    "    column_type_dict = {x:str(y[0]) for x,y in hdf_dataset.dtype.fields.items()}\n",
    "    column_list = []\n",
    "    for index in column_type_dict:\n",
    "        column_list.append(index)\n",
    "    list_of_rows = []\n",
    "    for line in range(0, hdf_dataset.size):\n",
    "        list_of_rows.append(np.asarray(hdf_dataset[line]).tolist())\n",
    "    return pd.DataFrame(data=list_of_rows, columns=column_list)\n",
    "\n",
    "def first_n_digits(num, n):\n",
    "    return num // 10 ** (int(math.log(num, 10)) - n + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in hdf5 data and convert to pandas format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data for 2018 to one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Data/HDF5data/weather/2018_weather.hdf5', 'r')\n",
    "dset_weather = file[\"WEATHER_SERVICE\"]\n",
    "dset_weather = dset_weather[\"IN\"]\n",
    "\n",
    "weather_dict_2018 = {}\n",
    "for key in dset_weather:\n",
    "    df_variable = dset_weather[key]\n",
    "    df_variable = df_variable['table']\n",
    "    weather_dict_2018[key] = hdf_to_pandas(df_variable)\n",
    "    \n",
    "    #shorten 64 to 32 bit integer\n",
    "    weather_dict_2018[key][\"index\"] = weather_dict_2018[key][\"index\"].apply(lambda x: first_n_digits(x, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data for 2019 to one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Data/HDF5data/weather/2019_weather.hdf5', 'r')\n",
    "dset_weather = file[\"WEATHER_SERVICE\"]\n",
    "dset_weather = dset_weather[\"IN\"]\n",
    "\n",
    "weather_dict_2019 = {}\n",
    "for key in dset_weather:\n",
    "    df_variable = dset_weather[key]\n",
    "    df_variable = df_variable['table']\n",
    "    weather_dict_2019[key] = hdf_to_pandas(df_variable)\n",
    "    \n",
    "    #shorten 64 to 32 bit integer\n",
    "    weather_dict_2019[key][\"index\"] = weather_dict_2019[key][\"index\"].apply(lambda x: first_n_digits(x, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data for 2020 to one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Data/HDF5data/weather/2020_weather.hdf5', 'r')\n",
    "dset_weather = file[\"WEATHER_SERVICE\"]\n",
    "dset_weather = dset_weather[\"IN\"]\n",
    "\n",
    "weather_dict_2020 = {}\n",
    "for key in dset_weather:\n",
    "    df_variable = dset_weather[key]\n",
    "    df_variable = df_variable['table']\n",
    "    weather_dict_2020[key] = hdf_to_pandas(df_variable)\n",
    "    \n",
    "    #shorten 64 to 32 bit integer\n",
    "    weather_dict_2020[key][\"index\"] = weather_dict_2020[key][\"index\"].apply(lambda x: first_n_digits(x, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat weather data, 2018-2020 for each parameter in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict = {}\n",
    "\n",
    "for parameter in weather_dict_2018:\n",
    "    weather_dict[parameter] = pd.concat([weather_dict_2018[parameter],weather_dict_2019[parameter],weather_dict_2020[parameter]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/weather/data_weather.pkl', 'wb') as f:\n",
    "    pickle.dump(weather_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/weather/data_weather.pkl', 'rb') as f:\n",
    "    weather_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Raw data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of available information of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in weather_dict:\n",
    "    print(str(parameter) + \" \" + str(len(weather_dict[parameter])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time resolution for temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'WEATHER_TEMPERATURE_TOTAL'\n",
    "weather_dict_2019[parameter].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict_2019[parameter]['time_difference'] = weather_dict_2019[parameter]['index'] - weather_dict_2019[parameter]['index'].shift(1)\n",
    "weather_dict_2019[parameter]['time_difference'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> No standardized time stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get load data index as reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/heatpump/data_heatpump.pkl', 'rb') as f:\n",
    "    load_dict = pickle.load(f)\n",
    "ref_index = load_dict['SFH10']['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for df_type in weather_dict:\n",
    "    df_ref = ref_index.to_frame().set_index('index')\n",
    "    df_ref[df_type] = np.nan\n",
    "    df_temp = weather_dict[df_type]\n",
    "    for index in ref_index:\n",
    "        sub_df = df_temp[(df_temp['index'] >= index) & (df_temp['index'] <= index+900)]\n",
    "        if sub_df.empty:\n",
    "            #take previous value\n",
    "            df_ref.loc[index][df_type] = df_ref.loc[index-900][df_type]\n",
    "        else:\n",
    "            #take mean value\n",
    "            df_ref.loc[index][df_type] = sub_df.iloc[:,1].mean()\n",
    "    df_list.append(df_ref)\n",
    "weather_data = pd.concat(df_list, axis=1)\n",
    "with open('Data/weather/data_weather_merged.pkl', 'wb') as f:\n",
    "    pickle.dump(weather_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/weather/data_weather_merged.pkl', 'rb') as f:\n",
    "    weather_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Weather data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame(columns=weather_data.columns, index=['min', 'max', 'mean', 'median', 'missing values'])\n",
    "for column in weather_data.columns:\n",
    "    df_analysis.loc['min'][column] = weather_data[column].min()\n",
    "    df_analysis.loc['max'][column] = weather_data[column].max()\n",
    "    df_analysis.loc['mean'][column] = weather_data[column].mean()\n",
    "    df_analysis.loc['median'][column] = weather_data[column].median()\n",
    "    df_analysis.loc['missing values'][column] = len(weather_data) - weather_data[column].value_counts().sum()\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plots = weather_data.copy()\n",
    "data_plots.reset_index(inplace=True)\n",
    "data_plots['index'] = pd.to_datetime(data_plots['index'], unit='s')\n",
    "data_plots.set_index('index', inplace=True)\n",
    "\n",
    "fig, a = plt.subplots(5, 2, figsize=(20, 20), tight_layout=True)\n",
    "data_plots.plot(ax=a, subplots=True, rot=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korrelation zwischen den einzelnen Wetterparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dict = {\n",
    "    'WEATHER_APPARENT_TEMPERATURE_TOTAL':           'Scheintemperatur',\n",
    "    'WEATHER_ATMOSPHERIC_PRESSURE_TOTAL':           'Luftdruck',\n",
    "    'WEATHER_PRECIPITATION_RATE_TOTAL':             'Niederschlag',\n",
    "    'WEATHER_PROBABILITY_OF_PRECIPITATION_TOTAL':   'Niederschlagswahrscheinlichkeit',\n",
    "    'WEATHER_RELATIVE_HUMIDITY_TOTAL':              'Relative Luftfeuchtigkeit',\n",
    "    'WEATHER_SOLAR_IRRADIANCE_GLOBAL':              'Sonneneinstrahlung',\n",
    "    'WEATHER_TEMPERATURE_TOTAL':                    'Temperatur',\n",
    "    'WEATHER_WIND_DIRECTION_TOTAL':                 'Windrichtung',\n",
    "    'WEATHER_WIND_GUST_SPEED_TOTAL':                'Windböenstärke',\n",
    "    'WEATHER_WIND_SPEED_TOTAL':                     'Windgeschwindigkeit'\n",
    "}\n",
    "\n",
    "\n",
    "correlation_matrix = weather_data.rename(columns=columns_dict).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Korrelationsmatrix')\n",
    "#plt.xlabel('Variablen')\n",
    "#plt.ylabel('Variablen')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Entfernen der Scheintemperatur sowie der Windböenstärke, da diese von der Absoluttemperatur sowie der Windgeschwindigkeit bereits gut erfasst werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_weather_data = weather_data.drop(columns=['WEATHER_APPARENT_TEMPERATURE_TOTAL', 'WEATHER_WIND_GUST_SPEED_TOTAL'], inplace=True)\n",
    "with open('Data/weather/data_weather_v1.pkl', 'wb') as f:\n",
    "    pickle.dump(reduced_weather_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
